{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>日期</th>\n",
       "      <th>股票代码</th>\n",
       "      <th>名称</th>\n",
       "      <th>收盘价</th>\n",
       "      <th>最高价</th>\n",
       "      <th>最低价</th>\n",
       "      <th>开盘价</th>\n",
       "      <th>前收盘</th>\n",
       "      <th>涨跌额</th>\n",
       "      <th>涨跌幅</th>\n",
       "      <th>换手率</th>\n",
       "      <th>成交量</th>\n",
       "      <th>成交金额</th>\n",
       "      <th>总市值</th>\n",
       "      <th>流通市值</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021/3/15</td>\n",
       "      <td>'600519</td>\n",
       "      <td>贵州茅台</td>\n",
       "      <td>1975.45</td>\n",
       "      <td>2069.80</td>\n",
       "      <td>1951.15</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2026.00</td>\n",
       "      <td>-50.55</td>\n",
       "      <td>-2.4951</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>6248487</td>\n",
       "      <td>12459955712</td>\n",
       "      <td>2.480000e+12</td>\n",
       "      <td>2.480000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021/3/12</td>\n",
       "      <td>'600519</td>\n",
       "      <td>贵州茅台</td>\n",
       "      <td>2026.00</td>\n",
       "      <td>2077.00</td>\n",
       "      <td>2002.01</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>2048.00</td>\n",
       "      <td>-22</td>\n",
       "      <td>-1.0742</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>4032251</td>\n",
       "      <td>8181594631</td>\n",
       "      <td>2.550000e+12</td>\n",
       "      <td>2.550000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021/3/11</td>\n",
       "      <td>'600519</td>\n",
       "      <td>贵州茅台</td>\n",
       "      <td>2048.00</td>\n",
       "      <td>2079.99</td>\n",
       "      <td>1961.48</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>1970.01</td>\n",
       "      <td>77.99</td>\n",
       "      <td>3.9589</td>\n",
       "      <td>0.4519</td>\n",
       "      <td>5676897</td>\n",
       "      <td>11521736384</td>\n",
       "      <td>2.570000e+12</td>\n",
       "      <td>2.570000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021/3/10</td>\n",
       "      <td>'600519</td>\n",
       "      <td>贵州茅台</td>\n",
       "      <td>1970.01</td>\n",
       "      <td>1999.87</td>\n",
       "      <td>1967.00</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>1936.99</td>\n",
       "      <td>33.02</td>\n",
       "      <td>1.7047</td>\n",
       "      <td>0.4074</td>\n",
       "      <td>5117174</td>\n",
       "      <td>10136910284</td>\n",
       "      <td>2.470000e+12</td>\n",
       "      <td>2.470000e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021/3/9</td>\n",
       "      <td>'600519</td>\n",
       "      <td>贵州茅台</td>\n",
       "      <td>1936.99</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>1900.18</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1960.00</td>\n",
       "      <td>-23.01</td>\n",
       "      <td>-1.174</td>\n",
       "      <td>0.6549</td>\n",
       "      <td>8226581</td>\n",
       "      <td>16100769579</td>\n",
       "      <td>2.430000e+12</td>\n",
       "      <td>2.430000e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          日期     股票代码    名称      收盘价      最高价      最低价     开盘价      前收盘  \\\n",
       "0  2021/3/15  '600519  贵州茅台  1975.45  2069.80  1951.15  2050.0  2026.00   \n",
       "1  2021/3/12  '600519  贵州茅台  2026.00  2077.00  2002.01  2070.0  2048.00   \n",
       "2  2021/3/11  '600519  贵州茅台  2048.00  2079.99  1961.48  1975.0  1970.01   \n",
       "3  2021/3/10  '600519  贵州茅台  1970.01  1999.87  1967.00  1977.0  1936.99   \n",
       "4   2021/3/9  '600519  贵州茅台  1936.99  2000.00  1900.18  1955.0  1960.00   \n",
       "\n",
       "      涨跌额      涨跌幅     换手率      成交量         成交金额           总市值          流通市值  \n",
       "0  -50.55  -2.4951  0.4974  6248487  12459955712  2.480000e+12  2.480000e+12  \n",
       "1     -22  -1.0742  0.3210  4032251   8181594631  2.550000e+12  2.550000e+12  \n",
       "2   77.99   3.9589  0.4519  5676897  11521736384  2.570000e+12  2.570000e+12  \n",
       "3   33.02   1.7047  0.4074  5117174  10136910284  2.470000e+12  2.470000e+12  \n",
       "4  -23.01   -1.174  0.6549  8226581  16100769579  2.430000e+12  2.430000e+12  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error  # 评价指标\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,GRU\n",
    "from keras import optimizers\n",
    "import keras\n",
    " \n",
    "import tensorflow as tf\n",
    " \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")#忽略一些警告 不影响运行 \n",
    "%matplotlib inline\n",
    " \n",
    " \n",
    "data=pd.read_csv(\"600519.csv\",encoding='gbk')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1975.45\n",
      "1       2026.00\n",
      "2       2048.00\n",
      "3       1970.01\n",
      "4       1936.99\n",
      "         ...   \n",
      "4737      37.01\n",
      "4738      37.10\n",
      "4739      36.38\n",
      "4740      36.86\n",
      "4741      35.55\n",
      "Name: 收盘价, Length: 4742, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data.columns\n",
    " \n",
    "data.drop(['股票代码','名称','日期','涨跌额','涨跌幅','成交金额','总市值','流通市值','成交量','换手率'],axis=1, inplace=True) # 删除操作 \n",
    " \n",
    "data.head()  # 删除无关紧要的特征 \n",
    " \n",
    "data.corr() # 计算相关系数 \n",
    " \n",
    "print(data[\"收盘价\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1975.45 2069.8  1951.15 2050.   2026.  ]\n",
      "(4742, 5)\n"
     ]
    }
   ],
   "source": [
    "data=np.array(data)\n",
    "print(data[0])\n",
    "print(data.shape)\n",
    " \n",
    " \n",
    "# 数据和标签\n",
    "train_x=[] # 特征 \n",
    "train_y=[]  # 标签 \n",
    " \n",
    "a=[]\n",
    "for i in range(0,4740,10):\n",
    "    a.append(data[int(i):int(i)+9])\n",
    "    train_x.append(a)\n",
    "    a=[]\n",
    "    train_y.append(data[int(i)+9:int(i)+10][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2058.   2456.43 2141.89 2160.9  1873.   1829.   1713.91 1730.05 1674.01\n",
      " 1699.  ]\n",
      "474\n",
      "474\n",
      "[[[1975.45 2069.8  1951.15 2050.   2026.  ]\n",
      "  [2026.   2077.   2002.01 2070.   2048.  ]\n",
      "  [2048.   2079.99 1961.48 1975.   1970.01]\n",
      "  [1970.01 1999.87 1967.   1977.   1936.99]\n",
      "  [1936.99 2000.   1900.18 1955.   1960.  ]\n",
      "  [1960.   2085.   1960.   2074.96 2060.11]\n",
      "  [2060.11 2095.   1988.   2000.   2033.  ]\n",
      "  [2033.   2096.   2010.1  2095.   2140.  ]\n",
      "  [2140.   2149.77 2033.   2040.   2058.  ]]]\n",
      "[[45.23 45.45 44.35 44.8  44.76]\n",
      " [44.76 45.3  44.12 44.2  44.28]\n",
      " [44.28 45.4  44.11 45.4  45.62]\n",
      " [45.62 46.52 44.9  46.5  46.77]\n",
      " [46.77 46.8  45.5  45.5  45.47]\n",
      " [45.47 45.5  44.76 44.99 44.92]\n",
      " [44.92 44.99 44.13 44.3  44.21]\n",
      " [44.21 44.5  43.8  44.2  44.08]\n",
      " [44.08 44.2  42.9  42.91 43.23]]\n",
      "--------------------------------------\n",
      "(379, 9, 5)\n",
      "(379, 1)\n",
      "(95, 9, 5)\n",
      "(95, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_y[0:10])\n",
    "print(len(train_y))\n",
    " \n",
    "print(len(train_x))\n",
    "print(train_x[0])\n",
    " \n",
    "# 定义归一化函数\n",
    "def data_guiyihua(data):\n",
    "    scaler =MinMaxScaler(feature_range=(0, 1))#指定参数的范围 进行归一化 \n",
    "    data_guiyihua=np.array(data) # 不进行归一化\n",
    "#     data_guiyihua_2 = data_guiyihua.reshape((data_guiyihua.shape[0], 1,data_guiyihua.shape[1]))\n",
    "    return data_guiyihua \n",
    " \n",
    " \n",
    "train_x=data_guiyihua(train_x)\n",
    "train_y=data_guiyihua(train_y)\n",
    " \n",
    "# 划分验证集和测试集\n",
    " \n",
    "x_train,x_test,y_train,y_test = train_test_split(np.array(train_x),np.array(train_y),test_size=0.2)\n",
    "#                                                                                         0.2 表示  八份训练 2份验证 懂吗？\n",
    "x_train=x_train.reshape(379,9,5)\n",
    "y_train=y_train.reshape(379,1)\n",
    "print(x_train[0])\n",
    "# x_train = x_train.astype(np.float32)\n",
    "# y_train =y_train.astype('float64')\n",
    "\n",
    "\n",
    "x_test=x_test.reshape(95,9, 5)\n",
    "y_test=y_test.reshape(95,1)\n",
    "# x_test = x_test.astype('float64')\n",
    "# y_test =y_test.astype('float64')\n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 100)               42400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 45,665\n",
      "Trainable params: 45,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 379 samples, validate on 379 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 115216.5814 - val_loss: 7916.4917\n",
      "Epoch 2/200\n",
      " - 0s - loss: 2703.3481 - val_loss: 744.9895\n",
      "Epoch 3/200\n",
      " - 0s - loss: 435.9785 - val_loss: 217.0535\n",
      "Epoch 4/200\n",
      " - 0s - loss: 194.9294 - val_loss: 97.4409\n",
      "Epoch 5/200\n",
      " - 0s - loss: 155.2395 - val_loss: 343.3254\n",
      "Epoch 6/200\n",
      " - 0s - loss: 323.0013 - val_loss: 307.5320\n",
      "Epoch 7/200\n",
      " - 0s - loss: 239.6221 - val_loss: 166.5178\n",
      "Epoch 8/200\n",
      " - 0s - loss: 159.5253 - val_loss: 198.1250\n",
      "Epoch 9/200\n",
      " - 0s - loss: 1244.2435 - val_loss: 1427.3596\n",
      "Epoch 10/200\n",
      " - 0s - loss: 2697.6098 - val_loss: 1307.3761\n",
      "Epoch 11/200\n",
      " - 0s - loss: 1073.5802 - val_loss: 1483.3448\n",
      "Epoch 12/200\n",
      " - 0s - loss: 1019.4350 - val_loss: 801.0914\n",
      "Epoch 13/200\n",
      " - 0s - loss: 535.9544 - val_loss: 302.9726\n",
      "Epoch 14/200\n",
      " - 0s - loss: 383.2158 - val_loss: 399.2398\n",
      "Epoch 15/200\n",
      " - 0s - loss: 509.2593 - val_loss: 645.2985\n",
      "Epoch 16/200\n",
      " - 0s - loss: 536.7186 - val_loss: 416.7073\n",
      "Epoch 17/200\n",
      " - 0s - loss: 476.1540 - val_loss: 455.4993\n",
      "Epoch 18/200\n",
      " - 0s - loss: 374.9303 - val_loss: 344.2348\n",
      "Epoch 19/200\n",
      " - 0s - loss: 477.2076 - val_loss: 543.6014\n",
      "Epoch 20/200\n",
      " - 0s - loss: 516.9269 - val_loss: 1065.6367\n",
      "Epoch 21/200\n",
      " - 0s - loss: 870.9014 - val_loss: 1167.0840\n",
      "Epoch 22/200\n",
      " - 0s - loss: 425.0873 - val_loss: 296.6279\n",
      "Epoch 23/200\n",
      " - 0s - loss: 370.9565 - val_loss: 329.3432\n",
      "Epoch 24/200\n",
      " - 0s - loss: 289.4540 - val_loss: 339.3495\n",
      "Epoch 25/200\n",
      " - 0s - loss: 254.3743 - val_loss: 309.2102\n",
      "Epoch 26/200\n",
      " - 0s - loss: 328.5158 - val_loss: 229.3593\n",
      "Epoch 27/200\n",
      " - 0s - loss: 258.1841 - val_loss: 314.5025\n",
      "Epoch 28/200\n",
      " - 0s - loss: 251.8370 - val_loss: 207.4066\n",
      "Epoch 29/200\n",
      " - 0s - loss: 258.2300 - val_loss: 396.8782\n",
      "Epoch 30/200\n",
      " - 0s - loss: 349.0442 - val_loss: 332.6810\n",
      "Epoch 31/200\n",
      " - 0s - loss: 351.5493 - val_loss: 200.2599\n",
      "Epoch 32/200\n",
      " - 0s - loss: 238.9656 - val_loss: 271.6153\n",
      "Epoch 33/200\n",
      " - 0s - loss: 193.9689 - val_loss: 362.8202\n",
      "Epoch 34/200\n",
      " - 0s - loss: 232.7257 - val_loss: 389.6791\n",
      "Epoch 35/200\n",
      " - 0s - loss: 228.5073 - val_loss: 238.7323\n",
      "Epoch 36/200\n",
      " - 0s - loss: 200.3473 - val_loss: 141.2686\n",
      "Epoch 37/200\n",
      " - 0s - loss: 202.9421 - val_loss: 407.4719\n",
      "Epoch 38/200\n",
      " - 0s - loss: 218.5782 - val_loss: 118.4784\n",
      "Epoch 39/200\n",
      " - 0s - loss: 111.8362 - val_loss: 106.6373\n",
      "Epoch 40/200\n",
      " - 0s - loss: 183.8790 - val_loss: 126.3682\n",
      "Epoch 41/200\n",
      " - 0s - loss: 167.3564 - val_loss: 350.0147\n",
      "Epoch 42/200\n",
      " - 0s - loss: 216.3305 - val_loss: 345.2076\n",
      "Epoch 43/200\n",
      " - 0s - loss: 248.9311 - val_loss: 134.2796\n",
      "Epoch 44/200\n",
      " - 0s - loss: 164.8906 - val_loss: 113.0441\n",
      "Epoch 45/200\n",
      " - 0s - loss: 151.3612 - val_loss: 120.9838\n",
      "Epoch 46/200\n",
      " - 0s - loss: 183.9593 - val_loss: 186.9654\n",
      "Epoch 47/200\n",
      " - 0s - loss: 151.8776 - val_loss: 170.8749\n",
      "Epoch 48/200\n",
      " - 0s - loss: 211.3715 - val_loss: 126.2188\n",
      "Epoch 49/200\n",
      " - 0s - loss: 206.4955 - val_loss: 117.1464\n",
      "Epoch 50/200\n",
      " - 0s - loss: 139.7823 - val_loss: 221.1308\n",
      "Epoch 51/200\n",
      " - 0s - loss: 204.3813 - val_loss: 191.7330\n",
      "Epoch 52/200\n",
      " - 0s - loss: 163.1578 - val_loss: 167.9631\n",
      "Epoch 53/200\n",
      " - 0s - loss: 129.5024 - val_loss: 141.3630\n",
      "Epoch 54/200\n",
      " - 0s - loss: 93.2307 - val_loss: 120.6319\n",
      "Epoch 55/200\n",
      " - 0s - loss: 104.5451 - val_loss: 105.8257\n",
      "Epoch 56/200\n",
      " - 0s - loss: 134.7489 - val_loss: 82.5177\n",
      "Epoch 57/200\n",
      " - 0s - loss: 111.0043 - val_loss: 78.1766\n",
      "Epoch 58/200\n",
      " - 0s - loss: 100.7529 - val_loss: 87.1290\n",
      "Epoch 59/200\n",
      " - 0s - loss: 78.2677 - val_loss: 78.8736\n",
      "Epoch 60/200\n",
      " - 0s - loss: 95.1308 - val_loss: 113.8777\n",
      "Epoch 61/200\n",
      " - 0s - loss: 94.0952 - val_loss: 109.8267\n",
      "Epoch 62/200\n",
      " - 0s - loss: 132.2743 - val_loss: 77.0510\n",
      "Epoch 63/200\n",
      " - 0s - loss: 137.9930 - val_loss: 75.9340\n",
      "Epoch 64/200\n",
      " - 0s - loss: 152.9332 - val_loss: 86.3146\n",
      "Epoch 65/200\n",
      " - 0s - loss: 111.1130 - val_loss: 109.0997\n",
      "Epoch 66/200\n",
      " - 0s - loss: 160.2345 - val_loss: 67.0151\n",
      "Epoch 67/200\n",
      " - 0s - loss: 91.4589 - val_loss: 88.9607\n",
      "Epoch 68/200\n",
      " - 0s - loss: 93.4200 - val_loss: 82.2646\n",
      "Epoch 69/200\n",
      " - 0s - loss: 75.4182 - val_loss: 73.1740\n",
      "Epoch 70/200\n",
      " - 0s - loss: 69.5663 - val_loss: 77.2126\n",
      "Epoch 71/200\n",
      " - 0s - loss: 117.3304 - val_loss: 90.7360\n",
      "Epoch 72/200\n",
      " - 0s - loss: 80.3257 - val_loss: 80.3491\n",
      "Epoch 73/200\n",
      " - 0s - loss: 110.3013 - val_loss: 112.5824\n",
      "Epoch 74/200\n",
      " - 0s - loss: 93.3257 - val_loss: 145.5692\n",
      "Epoch 75/200\n",
      " - 0s - loss: 92.0782 - val_loss: 181.7916\n",
      "Epoch 76/200\n",
      " - 0s - loss: 238.6815 - val_loss: 64.0658\n",
      "Epoch 77/200\n",
      " - 0s - loss: 91.4370 - val_loss: 89.8659\n",
      "Epoch 78/200\n",
      " - 0s - loss: 73.4879 - val_loss: 103.6269\n",
      "Epoch 79/200\n",
      " - 0s - loss: 92.9796 - val_loss: 118.1982\n",
      "Epoch 80/200\n",
      " - 0s - loss: 90.8438 - val_loss: 88.6709\n",
      "Epoch 81/200\n",
      " - 0s - loss: 67.2270 - val_loss: 67.5559\n",
      "Epoch 82/200\n",
      " - 0s - loss: 77.0643 - val_loss: 260.6079\n",
      "Epoch 83/200\n",
      " - 0s - loss: 152.3803 - val_loss: 102.1525\n",
      "Epoch 84/200\n",
      " - 0s - loss: 104.6401 - val_loss: 63.7914\n",
      "Epoch 85/200\n",
      " - 0s - loss: 82.4988 - val_loss: 124.7288\n",
      "Epoch 86/200\n",
      " - 0s - loss: 87.6183 - val_loss: 116.8842\n",
      "Epoch 87/200\n",
      " - 0s - loss: 157.6607 - val_loss: 156.7713\n",
      "Epoch 88/200\n",
      " - 0s - loss: 414.6024 - val_loss: 582.1915\n",
      "Epoch 89/200\n",
      " - 0s - loss: 363.0169 - val_loss: 299.5159\n",
      "Epoch 90/200\n",
      " - 0s - loss: 164.7316 - val_loss: 162.3899\n",
      "Epoch 91/200\n",
      " - 0s - loss: 154.7767 - val_loss: 89.0758\n",
      "Epoch 92/200\n",
      " - 0s - loss: 177.0182 - val_loss: 175.5492\n",
      "Epoch 93/200\n",
      " - 0s - loss: 103.6403 - val_loss: 84.6517\n",
      "Epoch 94/200\n",
      " - 0s - loss: 74.5650 - val_loss: 57.4384\n",
      "Epoch 95/200\n",
      " - 0s - loss: 76.1694 - val_loss: 97.1281\n",
      "Epoch 96/200\n",
      " - 0s - loss: 73.6881 - val_loss: 73.0777\n",
      "Epoch 97/200\n",
      " - 0s - loss: 64.2345 - val_loss: 63.3399\n",
      "Epoch 98/200\n",
      " - 0s - loss: 74.1510 - val_loss: 61.0779\n",
      "Epoch 99/200\n",
      " - 0s - loss: 66.1996 - val_loss: 59.8399\n",
      "Epoch 100/200\n",
      " - 0s - loss: 61.0406 - val_loss: 61.6736\n",
      "Epoch 101/200\n",
      " - 0s - loss: 58.4927 - val_loss: 114.5827\n",
      "Epoch 102/200\n",
      " - 0s - loss: 77.9243 - val_loss: 85.3712\n",
      "Epoch 103/200\n",
      " - 0s - loss: 167.5579 - val_loss: 125.0598\n",
      "Epoch 104/200\n",
      " - 0s - loss: 138.4009 - val_loss: 212.7012\n",
      "Epoch 105/200\n",
      " - 0s - loss: 133.5373 - val_loss: 85.2416\n",
      "Epoch 106/200\n",
      " - 0s - loss: 105.8499 - val_loss: 86.9713\n",
      "Epoch 107/200\n",
      " - 0s - loss: 108.7353 - val_loss: 224.6809\n",
      "Epoch 108/200\n",
      " - 0s - loss: 218.9803 - val_loss: 105.6965\n",
      "Epoch 109/200\n",
      " - 0s - loss: 252.7959 - val_loss: 421.9468\n",
      "Epoch 110/200\n",
      " - 0s - loss: 389.5549 - val_loss: 153.9056\n",
      "Epoch 111/200\n",
      " - 0s - loss: 139.3310 - val_loss: 146.6345\n",
      "Epoch 112/200\n",
      " - 0s - loss: 251.6403 - val_loss: 327.5483\n",
      "Epoch 113/200\n",
      " - 0s - loss: 139.5341 - val_loss: 81.4792\n",
      "Epoch 114/200\n",
      " - 0s - loss: 78.3386 - val_loss: 62.2028\n",
      "Epoch 115/200\n",
      " - 0s - loss: 59.4476 - val_loss: 103.7108\n",
      "Epoch 116/200\n",
      " - 0s - loss: 81.8099 - val_loss: 53.1666\n",
      "Epoch 117/200\n",
      " - 0s - loss: 136.8585 - val_loss: 112.7100\n",
      "Epoch 118/200\n",
      " - 0s - loss: 136.1123 - val_loss: 54.4421\n",
      "Epoch 119/200\n",
      " - 0s - loss: 68.6527 - val_loss: 133.1029\n",
      "Epoch 120/200\n",
      " - 0s - loss: 76.7988 - val_loss: 70.1930\n",
      "Epoch 121/200\n",
      " - 0s - loss: 59.2904 - val_loss: 64.8548\n",
      "Epoch 122/200\n",
      " - 0s - loss: 101.4993 - val_loss: 88.4148\n",
      "Epoch 123/200\n",
      " - 0s - loss: 95.7864 - val_loss: 53.4998\n",
      "Epoch 124/200\n",
      " - 0s - loss: 64.9111 - val_loss: 68.5827\n",
      "Epoch 125/200\n",
      " - 0s - loss: 67.8485 - val_loss: 50.4589\n",
      "Epoch 126/200\n",
      " - 0s - loss: 95.5165 - val_loss: 62.5167\n",
      "Epoch 127/200\n",
      " - 0s - loss: 86.5471 - val_loss: 79.2957\n",
      "Epoch 128/200\n",
      " - 0s - loss: 69.0395 - val_loss: 202.6530\n",
      "Epoch 129/200\n",
      " - 0s - loss: 102.7729 - val_loss: 69.7042\n",
      "Epoch 130/200\n",
      " - 0s - loss: 66.9096 - val_loss: 50.1552\n",
      "Epoch 131/200\n",
      " - 0s - loss: 60.7247 - val_loss: 49.4329\n",
      "Epoch 132/200\n",
      " - 0s - loss: 68.4817 - val_loss: 133.9842\n",
      "Epoch 133/200\n",
      " - 0s - loss: 117.6855 - val_loss: 107.9379\n",
      "Epoch 134/200\n",
      " - 0s - loss: 162.1902 - val_loss: 51.7571\n",
      "Epoch 135/200\n",
      " - 0s - loss: 104.2314 - val_loss: 66.8235\n",
      "Epoch 136/200\n",
      " - 0s - loss: 61.9894 - val_loss: 49.1856\n",
      "Epoch 137/200\n",
      " - 0s - loss: 71.4062 - val_loss: 60.1035\n",
      "Epoch 138/200\n",
      " - 0s - loss: 79.9896 - val_loss: 92.9839\n",
      "Epoch 139/200\n",
      " - 0s - loss: 77.2800 - val_loss: 51.3476\n",
      "Epoch 140/200\n",
      " - 0s - loss: 90.1283 - val_loss: 119.4362\n",
      "Epoch 141/200\n",
      " - 0s - loss: 84.7582 - val_loss: 47.5721\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f1ccc4c0b68c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m# model1.save_weights('lstmmoxing')#模型保存\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3792\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3794\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m     \"\"\"\n\u001b[1;32m-> 1605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1645\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_model_1():\n",
    "  model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(100,activation='relu', input_shape=(9,5)),\n",
    "    keras.layers.Dense(32 ,activation='relu'),# 全连接\n",
    "    keras.layers.Dense(1,activation='relu')# 1个全链接\n",
    "                      ])  \n",
    "#   model.compile(loss='binary_crossentropy', optimizer=op) 分类损失函数 和优化器 \n",
    "    \n",
    "  model.compile(loss='mean_squared_error', optimizer='adam')  # 回归损失函数和优化器 \n",
    "  return model\n",
    "op = optimizers.RMSprop(lr=0.001)\n",
    "model1 = create_model_1()\n",
    "model1.summary()\n",
    " \n",
    " \n",
    " \n",
    "model1.fit(x_train,y_train,validation_data=(x_train, y_train), epochs=200, batch_size=32,verbose=2, shuffle=True)\n",
    "# model1.save_weights('lstmmoxing')#模型保存\n",
    " \n",
    "# from sklearn.metrics import mean_squared_error #均方误差\n",
    "# from sklearn.metrics import mean_absolute_error #平方绝对误差\n",
    "# from sklearn.metrics import r2_score#R square\n",
    "# #调用\n",
    " \n",
    "# #引用上边的模型实例\n",
    "# model_jiazai_1 = create_model_1()\n",
    "# # 加载保存好的模型\n",
    "# model_jiazai_1.load_weights('lstmmoxing')\n",
    "# y1_pred_lstm = model_jiazai_1.predict(x_test)\n",
    "# for i in range(len(y1_pred_lstm )):\n",
    "#     print(\"真实收盘价：\",y_test[i])\n",
    "#     print(\"预测收盘价：\",y1_pred_lstm[i])\n",
    "#     print(\"-----------------------\")\n",
    " \n",
    "# print(mean_squared_error(y_test,y1_pred_lstm))\n",
    "# print(mean_absolute_error(y_test,y1_pred_lstm))\n",
    "# print(r2_score(y_test,y1_pred_lstm))\n",
    " \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
